
### You Only Look Once: Unified, Real-Time Object Detection  
#### Abstract  
我们提出YOLO，一个新的目标检测方法。之前有关对象检测的工作重新利用了分类器来执行检测。我们将对象检测框架化为空间分隔的边界框和相关类概率的回归问题。单个神经网络可以在一次评估中直接从完整图像中预测边界框和类概率。 由于整个检测管道是单个网络，因此可以直接在检测性能上进行端到端优化。  
我们的一体结构非常快。我们基本YOLO模型以45帧/s处理图像。一个小的网络版本，Fast YOLO，以惊人的155帧/s处理，但仍然实现其他实时检测器的双倍mAP（Mean Average Precision, mAP）。相比于目前最好的检测系统，YOLO会产生更多的定位错误，但预测背景的假阳性的可能性较小。最后，YOLO学习非常普遍的对象表示形式。 从自然图像推广到艺术品等其他领域时，它的性能优于其他检测方法，包括DPM和R-CNN。  
#### 1.Introduction  
人们看了一眼图像，立即知道图像中有什么对象，它们在哪里以及它们如何相互作用。人类的视觉系统快速而准确，使我们能够执行一些复杂的任务，例如无意识的驾驶。 快速，准确的对象检测算法将使计算机无需专用传感器即可驾驶汽车，使辅助设备向人类用户传达实时场景信息，并释放通用响应型机器人系统的潜力。  
当前的检测系统重新利用分类器来执行检测。为了检测物体，这些系统采用了该物体的分类器，并在测试图像的各个位置和比例上对其进行了评估。像DPM(deformable parts models)之类的系统使用滑动窗口方法，其中分类器在整个图像上均匀分布的位置运行。  
诸如R-CNN的最新方法使用区域提议方法，首先在图像中生成潜在的边界框，然后在这些提议的框上运行分类器。分类后，使用后期处理来精简边界框，消除重复的检测，并根据场景中的其他对象对框进行重新评分。这些复杂的流程缓慢且难以优化，因为每个单独的组件都必须分别进行训练。  
我们将对象检测重新构造为一个回归问题，直接从图像像素到边界框坐标和类概率。使用我们的系统，您只需看一次（YOLO）图像即可预测存在的物体及其位置。  
![图1](https://github.com/David-on-Code/Object-Detection/blob/master/YOLO/YOLO_V1/Fig1.png)
YOLO非常简单：请参见图1。单个卷积网络可同时预测多个边界框和这些框的类概率。 YOLO训练完整图像并直接优化检测性能。 与传统的对象检测方法相比，此统一模型具有多个优点。  
首先，YOLO非常快。由于我们将检测框架视为回归问题，因此不需要复杂的流程。我们只需在测试时在新图像上运行神经网络即可预测检测结果。我们的基本网络以每秒45帧的速度运行，在Titan X GPU上没有批处理，而快速版本的运行速度超过150 fps。这意味着我们可以以不到25毫秒的延迟实时处理流视频。而且，YOLO达到其他实时系统平均平均精度的两倍以上。有关在网络摄像头上实时运行的系统的演示，请参阅我们的项目网页：http://pjreddie.com/yolo/.   
其次，YOLO在做出预测时会全局考虑图像。与滑动窗口和基于区域提议的技术不同，YOLO在训练和测试期间会看到整个图像，因此它隐式地编码有关类及其外观的上下文信息。快速R-CNN是一种顶部检测方法，因为它看不到较大的上下文，因此将图像中的背景色块误认为是对象。 与Fast R-CNN相比，YOLO产生的背景错误少于一半。  
第三，YOLO学习对象的普遍表示。在自然图像上进行训练并在艺术品上进行测试时，YOLO在很大程度上优于DPM和R-CNN等顶级检测方法。 由于YOLO具有高度通用性，因此在应用于新域或意外输入时，失效的可能性较小。  
YOLO在准确性方面仍落后于最新的检测系统。 尽管它可以快速识别图像中的对象，但仍难以精确定位某些对象，尤其是小的对象。 我们在实验中进一步研究了这些权衡。  
#### 2.Unified Detection  
我们将对象检测的各个组成部分统一为一个神经网络。 我们的网络使用整个图像中的特征来预测每个边界框。 它还可以同时预测图像所有类的所有边界框。 这意味着我们的网络会全局考虑整个图像和图像中的所有对象。 YOLO设计可实现端到端的训练和实时速度，同时保持较高的平均精度。  
我们的系统将输入图像划分为S×S网格。如果对象的中心落入网格单元，则该网格单元负责检测该对象。  
每个网格单元预测B边界框和这些框的置信度得分。这些置信度得分反映出该模型对盒子包含一个对象的确信，以及它认为盒子预测的准确性。 我们正式定义置信度为$\(\operatorname{Pr}(\text { Object }) * \mathrm{IOU}_ {\text {pred }}^{\text {truth }}\)$。 如果该单元格中没有对象，则置信度分数应为零。 否则，我们希望置信度分数等于预测框与ground truth之间的联合相交（IOU）。   
每个边界框包含5个预测：x，y，w，h和置信度。（x，y）坐标表示框相对于网格单元边界的中心。相对于整个图像预测宽度和高度。 最后，置信度预测表示预测框与任何真实框之间的IOU。  
每个网格单元还可以预测C个条件类别的概率，$\(\operatorname{Pr}\left(\text { Class }_ {i} | \text { Object }\right)\)$.这些概率以包含对象的网格单元为条件。无论框B的数量如何，我们仅预测每个网格单元的一组类概率。无论框B的数量如何，我们仅预测每个网格单元的一组类概率。  
在测试时，我们将条件类别的概率与各个框的置信度预测相乘，$\begin{equation}
\operatorname{Pr}\left(\text { Class }_ {i} | \text { Object }\right) * \operatorname{Pr}(\text { Object }) * \mathrm { IOU}_ {\text {pred }}^{\text {truth}}=\operatorname{Pr}\left(\text { Class }_ {i}\right) * \text { IOU }_ {\text {pred}}^{\text {truth}}
\end{equation}$这为我们提供了每个box的特定类的置信度得分。 这些分数既编码了该类别出现在box中的概率和预测框适合对象的程度。  
![Fig2](https://github.com/David-on-Code/Object-Detection/blob/master/YOLO/YOLO_V1/Fig2.png)  
###### Model.  
我们的系统将检测建模为回归问题。将图像分成SxS的网格并且每个网格预测B个边框，为这些框设置置信度，并C类概率。这些预测编码为$S \times S \times(B * 5+C)$的张量
##### 2.1 Network Design
