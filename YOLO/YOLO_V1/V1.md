
### You Only Look Once: Unified, Real-Time Object Detection  
#### Abstract  
我们提出YOLO，一个新的目标检测方法。之前有关对象检测的工作重新利用了分类器来执行检测。我们将对象检测框架化为空间分隔的边界框和相关类概率的回归问题。单个神经网络可以在一次评估中直接从完整图像中预测边界框和类概率。 由于整个检测管道是单个网络，因此可以直接在检测性能上进行端到端优化。  
我们的一体结构非常快。我们基本YOLO模型以45帧/s处理图像。一个小的网络版本，Fast YOLO，以惊人的155帧/s处理，但仍然实现其他实时检测器的双倍mAP（Mean Average Precision, mAP）。相比于目前最好的检测系统，YOLO会产生更多的定位错误，但预测背景的假阳性的可能性较小。最后，YOLO学习非常普遍的对象表示形式。 从自然图像推广到艺术品等其他领域时，它的性能优于其他检测方法，包括DPM和R-CNN。  
#### 1.Introduction  
人们看了一眼图像，立即知道图像中有什么对象，它们在哪里以及它们如何相互作用。人类的视觉系统快速而准确，使我们能够执行一些复杂的任务，例如无意识的驾驶。 快速，准确的对象检测算法将使计算机无需专用传感器即可驾驶汽车，使辅助设备向人类用户传达实时场景信息，并释放通用响应型机器人系统的潜力。  
当前的检测系统重新利用分类器来执行检测。为了检测物体，这些系统采用了该物体的分类器，并在测试图像的各个位置和比例上对其进行了评估。像DPM(deformable parts models)之类的系统使用滑动窗口方法，其中分类器在整个图像上均匀分布的位置运行。  
诸如R-CNN的最新方法使用区域提议方法，首先在图像中生成潜在的边界框，然后在这些提议的框上运行分类器。分类后，使用后期处理来精简边界框，消除重复的检测，并根据场景中的其他对象对框进行重新评分。这些复杂的流程缓慢且难以优化，因为每个单独的组件都必须分别进行训练。  
我们将对象检测重新构造为一个回归问题，直接从图像像素到边界框坐标和类概率。使用我们的系统，您只需看一次（YOLO）图像即可预测存在的物体及其位置。  
![图1]()
YOLO非常简单：请参见图1。单个卷积网络可同时预测多个边界框和这些框的类概率。 YOLO训练完整图像并直接优化检测性能。 与传统的对象检测方法相比，此统一模型具有多个优点。  
